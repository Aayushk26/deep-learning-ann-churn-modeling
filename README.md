# Artificial Neural Networks, Deep Learning Churn Modeling

## Overview of Deep Learning: 
Introduction
- Neural networks & deep learning been around for some time. 60s and 70s invented, 80s caught wind with tons of research and thought it would solve all the world's problem...and then slowly died off in the next decade.
- Was it because they weren't good enough? Or was there another reason? Technology at the time was not at the standard to facilate neural networks. Need lots of data and processing power.
- Storage 
  - 1956 Hard drive (5 MB - Massive closet size, 2.5k to rent a month)
  - 1980 Hard drive (10 MB $3500) 
  - 2017 Hard drive (256 GB $149)
  - capacity of whatever was trending, 1956 -> 1980 = 2x, 1980 -> 2017 25,600x 
  - not a linear trend, exponential trend - logarithmic scale
  - DNA storage (future, $7k to synthesize 2MB of data, $2k to read it now)
  - 1kg of weight needed of DNA to store all of the world's data - 1 billion terabytes in one gram of DNA
  - Deep learning is picking up now since we have enough data now
  - Processing power - Moore's law - will lead to the Singularity (2023 Surpasses brainpower in humans, 2045 all the humans together)

What is Deep Learning?
- Geoffrey Hinton is the father of Deep Learning (research in 80s) Working at Google
- Idea behind deep learning is to look at the human brain, neuroscience, mimick how the human brain and recreate it. Humans brains are one of the most powerful learning tools in the world.
- Neurons - smeared onto glass - body, branches, tails, nucleus, etc. - 100 billion neurons in the human brain, each neuron is connected to a thousand or so of its neighbor. Cerebellum - motor/balance
- How to recreate this? Artificial Neural Networks - neurons/nodes
  - Input layer: value 1, Input value 2, Input value 3 
  - Output layer: value: (Fradulant transcations, etc)
  - Hidden layer: brain has so many neurons (ears, sense, eyes) going through billions of neurons before to output. 
  - Input later -> Hidden layer -> Output Layer
  - So why is this called Deep Learning? 
  - Shallow learning
  - Not just one hidden layer, multiple hidden layers, connect everything and interconnect, that's why we call it deep learning


Tooling
- Anaconda - prepackaged solutions, IDEs, most common packages, convenient package solution.
- Spyder (IDE) of choice z

## Artificial Neural Network (ANN) Intuition + Background
- Overview:
  - Neuron - how the human brain works
  - Activiation function - which one of them commonly used in neural network and which layer to use them
  - How do Neural Networks work? (example) - working first to see what we're aiming for, simplified version (real estate)
  - How do Neural Networks learn?
  - Gradient Descent
  - Stochastic Gradient Descent 
  - Backpropagation
- Neuron:
  - Neuron basic building blocks of ANNs
  - How can we recreate a neuron in a machine to mimick how the human brain work in the hopes of creating an infrastructure to learn. The human brain is one of the most powerful learning tool in the planet. 
  - First step of ANN is to recreate a Neuron
  - Neurons with lots of branches, thread coming out the bottom (1800s)
  - Neuron (body, dendrites - branches, axon - tail) - neuron by the itself is useless (like ants) but with lots of ants you can build a colony. With lots of neurons they can work together.
  - Axon is the transmitter, dendrites is the receptors, axon connects to the dendrites of the next neuron doesn't really touch - neurotransmitter molecules with receptor and synapse. How signal being passed synapse
  - Synapses is where signal is being passed
  - How we're going to represent neurons in machines? 
    - Neuron gets lots of input signals (X1, X2, Xm) and an output signal
    - Input layer think of it as analogy of the human brain (senses, sight, smell), your brain is only getting electrical impulses from our organs, lives in a dark black box and making sense of the world through input
    - Input layer passed through synapses
    - Neuron (hidden layer)
  - Input layers:
    - Independent variables (rows in DB - age, money, transporation, of a person)
    - Standardize the variables, sometimes want to normalize them -> want all of these variables to be similar and range of values, weights added up, neural networks if they're all the same is easier
    - Reading to learn more about standarization or normalization of variables: Yann LeCun et al., 1998, Efficient BackProp - http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf 
    - Output value
      - Continuous (price)
      - Binary (will exit yes/no)
      - Categorical (Output will be several y1, y2, y3)
    - Single Observation on left and right (input) and (right) rows
    - Linear regression or multi-variate linear regression (simplifying) -> one row correlated to that row
    - Synapses 
      - Assigned weights (w1, w2, Wm) 
      - Weights are crucial to ANN, how neural networks learn, adjusting weights what signal is important and what is not important to a neuron, what strength and what extent signals get passed along, weights are crucial and they're the ones that get adjusted. 
      - Weights in all the synapses, training in ANN => Gradient descent and back propogation come into play
    - Neuron
      - signals go into neuron
      - What happens inside the neuron?
        - 1) Weighted sum of all input values
        - 2) Applies an Activation Function - assigned to the layer (neuron), applied to weighted sum, neuron knows to whether to pass on signal on or not
        - 3) Passes that signal to the next neuron down the line
- Activation Function
  - Structure of a single neuron - input, weights, calculate weighted sum and applies activation function, and passes on signal (activation function)
  - What options do we have for activation function?
    - 1) Threshold Function
      - X-axis (Weighted sum of inputs)
      - Y-axis (0...1) 
      - If the value is less than 0, passes 0
      - If is more than 0, passes 1
      - Binary function (yes/no) 
    - 2) Sigmoid Function
      - sigmoid(x) 1/ (1 + e^-x)
      - logistic regression
      - good about smooth
      - vs. threshold doesn't have kinks, nice smoothing
      - useful for final layer (output layer) esp. predict probability
    - 3) Rectifier 
      - One of the most popular in ANN
      - Has a kink, but very popular
    - 4) Hyberbolic Tangent (tanh)
      - Similar to sigmoid -> goes below 0, might be useful
    - Additional reading activation functions - By Xavier Glorot et al., 2011, Deep sparse rectifier neural networks - http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf
      - You'll find why rectifier function is so heavily used 
      - Once you feel comfortable with the practical side of things, easier to soak the above
    - Recap: Threshould, Sigmoid, Rectifier, Hyperbolic Tangent
  - Ex. Assume the DV is binary (y = 0 or 1) which activation function would you be able to use? 
    - One neuron, an output value
    - 1. Threshold activation function (0 or 1) => perfectly fits
    - 2. Sigmoid activation function (also between 0 or 1, but has values in between) - but could be the probability of being 0 or 1, closer to the top more likely a 1, similar to logistic regression approach
  - Ex. Inputs layer, lots of hidden layer, to one output value
    - Most likely used is a rectifier function used in hidden layer
    - Output layer where sigmoid function will be used
- How do Neural Networks Learn?
  - Two fundamental different approaches to coding
    - Hard-coded coding, guide it the whole way and all options
    - Create a facility to understand what it needs to know alone, figure out alone
    - Example (How do you distinguish between Dog or Cats) 
      - Programming side (whisker, nose, ear, color for cats) conditions (ear are point cat)
      - Neural Network - code architecture, categorized data (go and learn what a dog and cat is), understand everything it needs to understand -> and learn from that
    - Single-layer Feed forward Neural Network (Perceptron)
      - y(hat) - predictive ouput value, y is actual output value
      - Input values supplied to neural network (perceptron) => activation function is applied to our output
      - Compare output value (Y(hat) to actual we need to get (Y value) 
      - Cost function C = 1/2 (y^ - y)^2 - mostly commonly used (gradient descent)
        - error in the prediction, minimize the cost function, closer y hat is to y
        - Cost function, compared the two, feed it back to the neural network and propogates to the weight and gets updated
        - what we have control of is to update the weight and tweak them
      - Again, we're only dealing with one row (Row ID, study hours, sleep, quiz, => predict (exam)) 
        - Yhat is change, cost is change, feed it back, weights gets adjusted
        - One more time, feed in information, yhat
        - Feed in that one row into neural network, weights, feed that information back to neural network, and minimize with cost function.
    - We've only been dealing with one row, now what if we have multiple rows
      - Example (8 rows) different students with (Row ID, Study Hrs, Sleep Hrs, Quiz, Exam)
      - Eight perceptron (all the same perceptron) - feeding into one neural network
      - One epoch - whole dataset and train neural network on all of the rows
      - Again, same neural network is being used
      - Feed into a row into neural network and get a value
      - Compare to actual value and now all these differences C = sum(1/2 (y^ - y)^2)
      - Full cost function adjust the weights now
      - All these perceptrons is just one neural network again
      - Weights will be shared among of them
      - Continue iteration, feed every single row, and find cost function (8000, 800,000 etc.)
      - Minimize the cost function is the goal
      - Minumum cost function found => Final neural networks achieved. Optimal weights achieved, ready to move forward to application or testing => This process is called backpropagation
      - Additional reading: CrossValidated, 2015, A list of cost functions used in neural networks, alongside applications -> https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications
- Gradient Descent
  - In order for a neural network to learn, backpropagation (sum of differences of yhat and y) is backpropagated to the neural networks and weights are adjusted.
  - Look at how weights are adjusted
  - How to minimize cost function?
    - 1. Brute force, try all possible => why not try brute force? Try 1000s of inputs for weight. One weight it might work, but increase number of weights and synapses you face the Curse of Dimensionality.
      - Curse of Dimensionality
        - Example (Neural Networks Housing example of how NN work) 
        - Before the weights are trained (all these possible synapes) 4 * 5 (25 weights) 
        - Look at how we could we brute force our way through it
        - 1,000 (for each weight) x 10000 x 1000 .... 1000  = 10000^24 10^75
        - June 2016 Sunway TaihuLight World's fast Super Computer (93 PFLOPS) Floating Operations pers seconds 93 x 10^15 FLOPS per second, average GFLOP for average computer
          - 19^75/ (93 * 10^15) 
          - 1.08 x 10^58 seconds = 3.42 x 10^50 years (older than universe)
        - What if multiple hidden layers? Never will happen
    - 2. Gradient Descent 
      - Slope at that specific point (negative then going down hill) 
        - means you need to go down hill
      - Slope is now positive (then go left -> roll the ball down)
      - Think of it as a ball rolling (not really more like zig zaggy)
      - More elements why does it go down why not upwards
        - parameters can be tweaked for the above
      - Instead of brute force, we can take a look at the slope with regards to the hill, less and less
      - Gradient descending to the mimumum of the cost function
- Stochastic Gradient Descent
  - Gradient descent is a very efficient method of solving our optimization of minimize our cost function, 10^57 to minutes/hours, which way is down hill, and get to the minimum faster
  - Cost function to convex, convex to one direction, one global minimum
  - What if cost function is not convex? How could that happen?
    - We don't choose cost function not the squared difference between yhat and y
    - or choose this but a multi-dimensional that is not convex
  - Local minimum rather than maximum => subpar neural network
  - What do we do here? => Stochastic Gradient Descent
  - Doesn't require cost function to be convex
  - Gradient Descent (Rows, same neural network, cost function, adjust weights, batch gradient descent)
  - Stochastic Gradient Descent 
    - Row by row we adjust the weights vs the whole epoch
  - Batch Gradient Descent vs. Stochastic Gradient Descent
    - SGD avoids the local minimum problem, function can afford higher fluctuations, much more likely to find the global minimum
    - SGD is actually faster because it doesn't have to wait memory to being loaded
    - BGD (pro) - deterministic algorithm, same starting weight, you'll get same results, iteration
    - Stochastic (random) updating neural network in a stochastic manner, different iterations to get there.
  - Also mini batch gradient descent (combination of the two) -> number of rows at a time
  - Further reading on gradient descent: Andrew Trask, 2015, A Neural Network in 13 lines of Python (Part 2 – Gradient Descent) - https://iamtrask.github.io/2015/07/27/python-network-part2/
    - Interesting thoughts on how to apply gradient descents, tips
  - Mathematics reading: Michael Nielsen, 2015, Neural Networks and Deep Learning - http://neuralnetworksanddeeplearning.com/chap2.html
- Backpropagation
  - We already know everything to know in a neural network
    - Forward Propagation (Input layer to hidden to ouput, yhat and errors)
    - Backpropagation - train network by adjusting the weight
  - Backpropagation - interesting, sophisticated mathematics that allow us to simulataneously adjust the weights
    - huge advantage (+) - during the process of backpropagation the way the algorithm is structured, each part of the weights the neural network is responsible for. Why it picked up so rapidly and was a major breakthrough, mathematics in the background
  - Intuition - adjusts all the weights at the same time
- Training the ANN with Stochastic Gradient Descent
  - 1. Randomly initalise the weights to small numbers close to 0 (but not 0)
    - Through forward propagation and back propagation weights are adjusted until the cost function is minimized
  - 2. Input the first observation of your dataset in the input layer, each feature in one input node.
    - take the columns and put them in input node.
  - 3. Forward-Propagation: from left to right, the neurons are activated in a way that the impact of each neuron's activation is limited by the weights (determine how important each neuron is). Propagate the activations until getting the predicted results y. 
  - 4. Compare the predicted result to the actual result. Measure the generated error. 
  - 5. Back-propagation: from right to left, the error is back-propagated. Update the weights according to how much they are responsible for the error. The learning rate decides by how much we update the weights.
  - 6. Repeat Steps 1 to 5 and update the weights after each observation (Reinforcement Learning, SGD). Or: Repeat Steps 1 to 5 but update the weights only after a batch of observations (Batch Learning, Minibatch)
  - 7. When the whole training set passed through the ANN, that makes an epoch. Redo more epochs. 
  - Steps to build an ANN
